{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prototype\n",
    "\n",
    "In dit bestand is het prototype voor de brandweer opgezet. Om het prototype op te zetten zijn verschillende stappen uitgevoerd die per onderdeel worden uitgelicht. Hierin wordt uitgelicht welke keuzes er gemaakt zijn om de stappen uit te kunnen voeren.\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Data preparatie\n",
    "Vanuit de brandweer regio Rotterdam-Rijnmond zijn video's verkregen van vijf incidenten. Tijdens deze incidenten is er gevlogen met een drone om de videobeelden te kunnen maken. Hierin wordt van bovenaf gefilmd waarbij de locatie met omgeving en de brand in kaart wordt gebracht. Vorodat de data in het transfer learning model getraind kan worden is het nodig om de data te labelen. Om dit te kunnen doen wordt gebruik gemaakt van object detectie om zowel de objecten in de omgeving als de brand met bijbehorende rook te labelen. Hiervoor is gebruik gemaakt van het Yolo model versie 5."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Als eerst is het yolo model gedownload met de volgende code: pip install yolov5. Vervolgens zijn in de terminal de objecten rook en vuur getraind met de D-Fire dataset (Gaiasd, z.d.). De video's van de brandweer zijn vervolgens gedetecteer op de getrainde objecten vuur en rook. De video's waarin deze objecten gedetecteerd worden zijn vervolgens lokaal opgeslagen en met deze video's wordt vervolgens het oppervlak per boudning box bepaald. De eerste stap is hierin om per frame de grootte van de bounding boxes te bepalen. Dit is uitgevoerd moet onderstaande code. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in C:\\Users\\cboxm/.cache\\torch\\hub\\ultralytics_yolov5_master\n",
      "YOLOv5  2023-5-25 Python-3.10.6 torch-2.0.1+cpu CPU\n",
      "\n",
      "Fusing layers... \n",
      "YOLOv5s summary: 213 layers, 7225885 parameters, 0 gradients\n",
      "Adding AutoShape... \n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from PIL import Image\n",
    "import cv2\n",
    "\n",
    "# laden van het Yolov5 model\n",
    "model = torch.hub.load('ultralytics/yolov5', 'yolov5s')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Het openen van het videobestand\n",
    "video_path = 'cboxm/yolov5/runs/detect/exp11/DJI_20130118095545_0002_W.mp4'\n",
    "video = cv2.VideoCapture(video_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Opsplitsen van frames in de video\n",
    "while True:\n",
    "    # Het frame lezen\n",
    "    ret, frame = video.read()\n",
    "\n",
    "    # De loop wordt onderborken als de video is afgelopen\n",
    "    if not ret:\n",
    "        break\n",
    "\n",
    "    # Omzetten naar een afbeelding\n",
    "    image = Image.fromarray(cv2.cvtColor(frame, cv2.COLOR_BGR2RGB))\n",
    "\n",
    "    # Verwijzing naar afbeelding maken\n",
    "    results = model(image)\n",
    "\n",
    "    # Coordinaten van de bounding box\n",
    "    bounding_boxes = results.pred[0].xyxy\n",
    "\n",
    "    # Herhalen voor ieder object\n",
    "    for box in bounding_boxes:\n",
    "        x1, y1, x2, y2, conf, cls = box.tolist()\n",
    "\n",
    "        # Printen van de bounding boxes met labels\n",
    "        print(f\"Frame: {frame_number}, Box: [{x1}, {y1}, {x2}, {y2}], Confidence: {conf}, Class: {cls}\")\n",
    "\n",
    "    # Het frame van de bounding boxes weergeven\n",
    "    cv2.imshow('Video', frame)\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "# Video genereren\n",
    "video.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Model voor labelen highlights\n",
    "\n",
    "Naast het labelen van de highlights kan de video ook worden versneld om een verandering in de objecten vuur en rook te kunnen weergeven voor een Officier van Dienst. Met de volgende code is een video versneld."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fps: 29.97002997002997\n",
      "fps: 149.85014985014985\n",
      "Moviepy - Building video runs/detect/exp11/DJI_20130118095545_0002_W_out.mp4.\n",
      "Moviepy - Writing video runs/detect/exp11/DJI_20130118095545_0002_W_out.mp4\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                  \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Moviepy - Done !\n",
      "Moviepy - video ready runs/detect/exp11/DJI_20130118095545_0002_W_out.mp4\n"
     ]
    }
   ],
   "source": [
    "from moviepy.editor import VideoFileClip\n",
    "import moviepy.video.fx.all as vfx\n",
    "\n",
    "# Ophalen video en definieren locatie versnelde video\n",
    "video_path = 'runs/detect/exp11/DJI_20130118095545_0002_W.mp4'\n",
    "video_out = 'runs/detect/exp11/DJI_20130118095545_0002_W_out.mp4'\n",
    "\n",
    "# Importeren van de video in VideoFileClip\n",
    "clip = VideoFileClip(video_path)\n",
    "print(\"fps: {}\".format(clip.fps))\n",
    "\n",
    "# De FPS aanpassen\n",
    "clip = clip.set_fps(clip.fps * 5)\n",
    "\n",
    "# Versnellen van de video\n",
    "final = clip.fx(vfx.speedx, 5)\n",
    "print(\"fps: {}\".format(final.fps))\n",
    "\n",
    "# Opslaan van de video\n",
    "final.write_videofile(video_out)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Model trainen\n",
    "\n",
    "Het transfer learning model wordt getraind met het voorafgetraind ConvNet model. Het model bestaat uit een encoder en een decoder die ervoor zorgen dat voorspellingen op de videoframes gemaakt kunnen worden. In dit onderzoek wordt voorspelt of een frame een highlight is die meegenomen moet worden in de videosamenvatting. Door alle frames die voorspeld zijn als highlight achter elkaar te zetten ontstaat een videosamenvatting."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
